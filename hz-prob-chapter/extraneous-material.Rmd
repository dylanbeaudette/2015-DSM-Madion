### Issues to be resolved
* estimation of confidence intervals via GAMM ? [ideas here](http://www.fromthebottomoftheheap.net/2014/06/16/simultaneous-confidence-intervals-for-derivatives/)

* how can we simulate from a model developed by `orm()`? See `stats:::simulate.lm` for ideas.

* are we violating any assumptinos of PO logistic regression ? [ideas](http://www.ats.ucla.edu/stat/r/dae/ologit.htm) and [more info](http://www.kenbenoit.net/courses/ME104/ME104_Day8_CatOrd.pdf)

* how can we accomodate the lower effective DF due to massive autocorrelation within "sliced" data? (GEE approach as suggested by Frank Harrell)

* does it make more sense to use the original horizons, and then add thickness weights-- or use the sliced data? I like the slicing approach, but it does give unreasonably small standard error estimates for coefficients.

* use of ordered factors does not change the results of `orm()` and `slab()` barfs with them.

* slice-wise eval of predicted genhz via [Brier Score](http://en.wikipedia.org/wiki/Brier_score#cite_note-Brier-1), or even better: `verification::rps()` for ranked probability scores

* [this method](http://cran.r-project.org/web/packages/ordinal/vignettes/clm_intro.pdf) gives identical models to `orm()`, however the `ordinal` package has some additional features. It is not clear how the "threshold coefficients" could be used:

```
Threshold coefficients:
        Estimate Std. Error z value
A|BA      1.3081     0.1002   13.06
BA|Bt1    2.0080     0.1044   19.24
Bt1|Bt2   6.1038     0.1906   32.03
Bt2|Bt3   9.8494     0.2398   41.07
Bt3|Cr   12.3512     0.2515   49.10
Cr|R     15.1321     0.2652   57.05
```


### Simulation from GHL Probabilities [this doesn't work, consider leaving out]
```{r simulation-from-model, fig.width=10, fig.height=5}
# simulate GHL at each depth-slice, using probabilities from PO-model
p.sim <- apply(p, 1, function(i) sample(hz.names, size = 10, replace = TRUE, prob = i[hz.names]))

# check... not quite right, too much noise in the predictions
t(p.sim)[1:10, ]
```



### Simultaneous confidence intervals for derivatives of splines in GAMs
not yet ready for prime time...


```{r gamms, eval=FALSE}
## Load mgcv and fit the model
require(mgcv)

# method setup
ctrl <- list(
  niterEM = 0, 
  msVerbose = FALSE, 
  optimMethod="L-BFGS-B"
)

# fitting model
m2 <- gamm(
  formula = value ~ s(top),
  data = subset(g, variable == 'A'), 
  correlation = corARMA(form = ~ 1 | top, p = 2),
  control = ctrl
)

## prediction data
want <- seq(1, nrow(subset(g, variable == 'A')), length.out = 200)
pdat <- with(subset(g, variable == 'A'), data.frame(top = top[want]))

## download the derivatives gist
# tmpf <- tempfile()
# download.file("https://gist.githubusercontent.com/gavinsimpson/ca18c9c789ef5237dbc6/raw/295fc5cf7366c831ab166efaee42093a80622fa8/derivSimulCI.R", tmpf, method = "wget")
# source(tmpf)

library(MASS)

lp <- predict(m2$gam, newdata = pdat, type = "lpmatrix")
coefs <- coef(m2$gam)
vc <- vcov(m2$gam)

set.seed(35)
sim <- mvrnorm(25, mu = coefs, Sigma = vc)

want <- grep("top", colnames(lp))

fits <- lp[, want] %*% t(sim[, want])
dim(fits) ## 25 columns, 1 per simulation, 200 rows, 1 per evaln point

ylims <- range(fits)
plot(value ~ top, data = subset(g, variable == 'A'), pch = 19, ylim = ylims, type = "n")
matlines(pdat$top, fits, col = rgb(0.1, 0.1, 0.1, alpha=0.25), lty = 1)

```

