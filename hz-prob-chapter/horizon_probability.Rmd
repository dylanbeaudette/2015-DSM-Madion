---
title: "Aggregate Representation of Genetic Soil Horizons"
author: D.E. Beaudette, P. Roudier and J.M. Skovlin
fontsize: 11pt
output:
  html_document:
    fig_caption: yes
    number_sections: yes
    theme: journal
  pdf_document:
    fig_caption: yes
  word_document:
    fig_caption: yes
bibliography: bibliography.bib
---

```{r setup, echo=FALSE, results='hide'}
# options for knitr
library(knitr, quietly = TRUE)
opts_chunk$set(message=FALSE, warning=FALSE, background='#F7F7F7', dpi=100, fig.align='center', dev='png', dev.args=list(pointsize=10, type='cairo', antialias='subpixel'), tidy=TRUE)

# options for R session
options(width=100, stringsAsFactors=FALSE)
```

# Abstract

Published soil survey reports typically describe soils in terms of aggregate information: soil properties, interpretations, and limitations that are based on a collection of field-described soil profiles. 
While aggregate soil properties are readily estimated via standard statistical functions (mean, median, etc.), an aggregate representation of horizonation (e.g. genetic or functional horizon designation and depth) is typically difficult to construct. 
Variation in horizon designation among different soil scientists and different soil description systems, changes in horizon designation standards over time, variable depths at which horizons occur, and the various uncertainties associated with these are all factors that complicate the process of delivering an aggregate representation of horizonation. 
In this paper we propose alternatives to the typical "representative profile" -- e.g. the selection of a single soil profile to represent a collection. Two possible methods for aggregating a collection of soil profiles into synthetic profiles are presented, describing depth-wise probability functions for each horizon. 
Both methods rely on an expert-guided description of generalized horizon designation (e.g. a subset of horizon designation labels that convey a reasonable "morphologic story") along with associated rules (regular expression patterns) used to correlate field-described to generalized horizon designation. 
The first method is based on (1-cm interval) slice-wise evaluation of generalized horizon designation; the second is based on a proportional-odds logistic regression model fit to depth-slices. 
These methods are demonstrated using USDA-NRCS soil survey data (USA). 

```{r libraries, echo=FALSE, message=FALSE}
# libraries
library(aqp)
library(latticeExtra)
library(rms)
library(plyr)
library(reshape)
library(scales)
library(cluster)
library(knitr)
library(ggplot2)
```

```{r data, echo=FALSE}
# load sample data
data(loafercreek, package = 'soilDB')

# discreet colors used to plot horizon probability depth-functions
cols <- c('black', grey(0.33), 'goldenrod4', 'orange', 'orangered', 'chocolate', 'green', 'blue')
```

# Introduction

Published soil survey reports typically describe soils in terms of *aggregate* information, *ie* soil properties, interpretations, and limitations that are based on a collection of field-described soil profiles. 
While aggregate soil properties are readily estimated via standard statistical functions (mean, median, etc.), an aggregate representation of *horizonation* (e.g. genetic horizon designation and depth) is typically difficult to construct [@beaudette2013]. 
Variation in horizon designation "style" among different soil scientists, changes in horizon designation standards over time, variable depths at which genetic horizons occur, and the possible lack of a specific genetic horizon are all factors that complicate the process of delivering an aggregate representation of horizonation. 

* Horizonation as assessed by soil scientists is somewhat subjective, and there is always some error associated with it. This error is rarely acknowledged: boundaries between horizons, expressed as horizon depths, are generally considered as "crisp" numbers, while in actuality they represent "fuzz" numbers. 
* At this stage of the introduction it would be good to explain how traditional aggregates (mean, etc) only gets you so far. Soil profile is a fundamental object for the understanding of soil processes, so it's important to come up w/ statistical/quantitative aggregate for these. Link this with importance of pedological understanding of soil, and with making a truly useful product out of soil survey data. 

We demonstrate two possible methods for aggregating a collection of soil profiles into "synthetic profiles"; describing depth-wise probability functions for each genetic horizon. 
Both methods rely on an expert-guided description of generalized horizon designation (e.g. horizon designations that are deemed representative) along with associated rules (regular expression patterns) used to correlate field-described to generalized horizon designation. 
The first method is based on (1-cm interval) slice-wise evaluation of generalized horizon designation; the second is based on a proportional-odds logistic regression model fit to depth-slices. Specialized classes for soil profile collections and depth-slicing algorithms are implemented in the [aqp](http://cran.at.r-project.org/web/packages/aqp/index.html) package for R [C&G reference here]. 

Papers to cite:

* horizon thickness [@Vanwalleghem2010]
* "red clay" hz presence, logistic regression [@Evans2014296]
* depth-functions [@myers2011,@Kempen2011]
* morphometrics [@Hartemink2014]

Other:

* examples: http://www.stat.ufl.edu/~aa/ordinal/R_examples.pdf

# Materials and Methods

## Soil Profile Data

A collection of (`r length(loafercreek)`) soil profiles from the Sierra Foothill region of California were used to demonstrate two approaches for determining aggregate representation of genetic horizon boundaries. [INSERT DESCRIPTION OF RAINFALL, LOCATION, ETC] 

![alt text](static-figures/mvo-soil-montage-narrow.jpg)

These soil profiles represent some of the data that have been "correlated" to the [Loafercreek](https://soilseries.sc.egov.usda.gov/OSD_Docs/L/LOAFERCREEK.html) soil series. 
These data are included within the **soilDB** package for R [@beaudette2015]. 

## Horizon Generalization

```{r pro-genz, echo=FALSE, results='hide', cache=TRUE}
# graphical range in horizon mid-point, sorted by class-wise median depth
loafercreek$mid <- with(horizons(loafercreek), (hzdept + hzdepb) / 2)
hz.designation.by.median.depths <- names(sort(tapply(loafercreek$mid, loafercreek$hzname, median)))

# generalize horizon names using REGEX rules
n <- c('Oi', 'A','BA','Bt1','Bt2','Bt3','Cr','R')
p <- c('O', '^A$|Ad|Ap|^ABt$','AB$|BA$|Bw', 'Bt1$|^Bt$|^B$','^Bt2$','^Bt3|^Bt4|CBt$|BCt$|2Bt|2CB$|^C$','Cr','R')
loafercreek$genhz <- generalize.hz(loafercreek$hzname, n, p)

# remove non-matching generalized horizon names
loafercreek$genhz[loafercreek$genhz == 'not-used'] <- NA
loafercreek$genhz <- factor(loafercreek$genhz)

# keep track of generalized horizon names for later
hz.names <- levels(loafercreek$genhz)
```

Generalized horizon labels (GHL) represent an expert-guided selection of generalized horizon designations that were consistently observed in the field, and meaningful in terms of soil morphology and management [REFERENCE TO THE NRCS SOIL SURVEY GUIDE??].  
These designations were determine to convey the "morphologic story" or conceptual framework of most-likely horizons typically observed in a suite of soil profiles. 
The Official Series Description (OSD, [https://soilseries.sc.egov.usda.gov/OSD_Docs/L/LOAFERCREEK.html]) of the Loafercreek series typical pedon and range in characteristics defines this soil series concept. 

Once a set of GHL have been determined (```r c('Oi', 'A','BA','Bt1','Bt2','Bt3','Cr','R')```), a corresponding set of regular expression (REGEX) rules were developed to map the field-described designations into generalized designations. 
This process typically requires expert-guided review of: 1) regional patterns in horizonation style, 2) morphologic property differences by groups of field-described designation, and, 3) patterns of horizonation and properties with depth. 
The expert's field experience is thus preserved within the vector of REGEX rules. 

## Horizon Aggregation by Slicing

Slicing and slice-wise evaluation of horizon probability described in [AQP: A Toolkit for Soil Scientists](10.1016/j.cageo.2012.10.020).

```{r pro-slice, echo=FALSE, cache=TRUE}
# slice out color and horzizon name into 1cm intervals: no aggregation
max.depth <- 150
slice.resolution <- 1
slice.vect <- seq(from = 0, to = max.depth, by = slice.resolution)
s <- slice(loafercreek, slice.vect ~ soil_color + genhz)

# convert horizon name to factor
s$genhz <- factor(s$genhz, levels = hz.names)

# compute slice-wise probability: slice-wise P always sum to 1
# BUG: this doesn't work with ordered factors
a <- slab(loafercreek, ~ genhz, cpm=1)

# convert to long-format for plotting
a.long <- melt(a, id.vars='top', measure.vars=hz.names)
```


## Horizon Aggregation by Proportional-Odds Logistic Regression

proportional-odds (PO) logistic regression
$$ P[Y \geq j | X] = \frac{1}{1 + exp[-(\alpha_{j} + X \beta]} $$
Extension of logistic regression model; predictions constrained by horizon designation and order. RCS basis functions accommodate non-linearity.

```{r pro-po-model, echo=FALSE, cache=TRUE, results='hide'}
# proportional-odds logistics regression: fits well, ignore standard errors
# using sliced data properly weights observations... but creates optimistic SE
# rcs required when we include depths > 100 cm...
# should we use penalized PO-LR? see pentrace()
dd <- datadist(horizons(s)) ; options(datadist="dd")
l.genhz <- orm(genhz ~ rcs(hzdept), data=horizons(s), x=TRUE, y=TRUE)

# predict along same depths: columns are the class-wise probability
# fitted.ind --> return all probability estimates
p <- data.frame(predict(l.genhz, data.frame(hzdept=slice.vect), type='fitted.ind'))

# re-name, rms model output give funky names
names(p) <- hz.names

# add depths
p$top <- slice.vect

# melt to long format for plotting
p.long <- melt(p, id.vars='top', measure.vars=hz.names)

# combine sliced data / predictions
g <- make.groups(sliced.mode.1 = a.long, PO.model = p.long)
g$which <- factor(g$which, labels=c('empirical probabilities', 'PO-logistic regression'))

# remove P(hz) < 0.5%
g$value[which(g$value < 0.005)] <- NA

## compute ML horizons by slice

# extract ML-horizon boundaries 
a.ml <- get.ml.hz(a, hz.names)
p.ml <- get.ml.hz(p, hz.names)

# generate ordering vector of loafrcreek based on GHL similarity
a.slab.id <- slab(loafercreek, peiid ~ genhz, cpm=1)
depths(a.slab.id) <- peiid ~ top + bottom
d <- profile_compare(a.slab.id, vars=hz.names, max_d=140, k=0)
h <- diana(d)

# Shannon's H index for po-lr model, computed by depth-slice
# using a log base of length(hz.names) constrains the value to 0--1
shannon.h <- apply(p[, hz.names], 1, function(i) -sum(i*log(i, base = length(hz.names))))

# generate NA-free values/predictions for Brier Score calc
s.sub <- horizons(s)[, c('genhz', 'hzdept')]
p.s  <- data.frame(predict(l.genhz, s.sub, type='fitted.ind'))

# re-name, rms model output give funky names
names(p.s) <- hz.names

# combine original data + predictions
p.s <- cbind(s.sub, p.s)

# eval Brier Score by gen hz
# note that predictions at any given depth slice will always be the same
p.bs <- ddply(p.s, 'genhz', function(x.i) {
  # save the gen hz probabilities into new df
  x.pr <- x.i[, hz.names]
  # init new matrix to store most-likely gen hz class
  m <- matrix(0, ncol=ncol(x.pr), nrow=nrow(x.pr))
  # same structure as x.pr
  dimnames(m)[[2]] <- names(x.pr)
  # set appropriate genhz to 1
  for(i in 1:nrow(x.i)) {
    ml.hz.i <- x.i$genhz[i]
    m[i, ml.hz.i] <- 1
    }
  # compute bs for this gen hz
  bs <- sum((x.pr - m)^2, na.rm=TRUE) / nrow(x.pr)
  })

# fix names
names(p.bs) <- c('genhz', 'brier.score')

# remove NAs from table
p.bs <- na.omit(p.bs)

# add fake prob for plotting along x-axis of depth vs. prob
p.s$fake.prob <- 1.1
```

## Model stability

PO-model stability was evaluated by repeatedly re-fitting a model to 25 randomly sampled profiles (out of 53 total), 250 times. 
ML horizon boundaries were derived from these data by evaluating the 5th-50th-95th percentiles of ML horizon boundaries computed within each simulation. 

```{r pro-model-robustness, echo=FALSE, cache=TRUE}
# encapsulate model fitting / prediction within a single function
f.test <- function(s.i, slice.vect, hz.names) {
	# fit model to a subset of the original data
	l.genhz <- try(orm(genhz ~ rcs(hzdept), data=horizons(s.i)))
	
	# sometimes the subset doesn't permit model fitting, in that case return NULL
	if(inherits(l.genhz, 'try-error'))
		return(list(predictions=NULL, model.disc.index=NULL))
	
	# otherwise generate predictions
	p <- data.frame(predict(l.genhz, data.frame(hzdept=slice.vect), type='fitted.ind'))
	names(p) <- hz.names
	p$top <- slice.vect
	
	p.long <- melt(p, id.vars='top', measure.vars=hz.names)
	mdi <- l.genhz$stats['R2']
	
	return(list(predictions=p.long, model.disc.index=mdi))
}

# init an empty list
n.reps <- 250
l.res <- list()

## TODO: it would be nice to evaluate the model at each iteration using
##       those observations that were left out
# loop a bunch of times, re-fitting the model to a subset of only 25 profiles
for(i in 1:n.reps) {
	len.vect <- 1:length(loafercreek)
	s.idx <- sample(len.vect, size=25, replace=FALSE)
	# s.left.out.idx <- setdiff(len.vect, s.idx)
	l.res[[paste('rep.', i, sep='')]] <- f.test(s[s.idx, ], slice.vect, hz.names)
}

# convert the result from a list into a data.frame, and remove very small probs.
d.res <- ldply(l.res, function(i) i$prediction)
d.res$value[which(d.res$value < 0.01)] <- NA

# extract model discrimination index
res.mdi <- unlist(sapply(l.res, function(i) i$model.disc.index))
```

## Quantification of Uncertainty

Shannon Entropy (H index)
$$ H = -\sum_{i=1}^{n}{p_{i} * log_{n}(p_{i})}  $$
$H$ is an index of uncertainty associated with predicted probabilities, $\mathbf{p}$, of encountering horizons $i$ through $n$ at some depth. Larger values suggest **more** confusion.

Brier scores
$$ B = \frac{1}{n} \sum_{i=1}^{n}{ ( p_{i} - y_{i} )^{2}  }  $$
$B$ is an index of agreement between predicted probabilities, $\mathbf{p}$, and horizons, $\mathbf{y}$, over depth-slices $i$ through $n$ associated with a specific horizon. Larger values suggest **less** agreement between probabilities and observed horizon labels.

# Results

## Horizon labels generalisation

```{r fig-horizonation, fig.width=6, fig.height=5, echo=FALSE, fig.cap='CAPTION ME'}
# check on existing horizonation
barplot(sort(table(loafercreek$hzname), decreasing=TRUE), ylab = "Number of horizons", cex.names=0.5)
```

```{r fig-eval-horizonation, fig.width=10, fig.height=5, echo=FALSE, fig.cap='CAPTION ME'}
hz_lfc <- horizons(loafercreek)
hz_ordered <- c('Oi', 'Ap', 'A', 'Ad', 'ABt', 'AB', 'BA', 'Bw', 'Bt1', 'B', 'Bt', 'Bt2', '2Bt2', '2Bt3', 'CBt', '2BCt', 'Bt3', 'C', '2CB', 'Bt4', '2Bt4', 'BCt', 'Cr', 'Crt', '2Crt', '2Cr', 'Rt', 'R', '2R')
hz_lfc$hzname <- factor(hz_lfc$hzname, levels = hz_ordered)

# Making group 
ggplot(data = hz_lfc) +
  geom_boxplot(aes(x = hzname, y = mid, fill = genhz)) +
  scale_fill_manual(values = cols) +
  scale_y_reverse() +
  guides(fill = guide_legend(title = "Generalized\nHorizon\nLabel")) +
  labs(x = "Original Horizon Designation", y = "Horizon Mid-Point Depth (cm)") +
  theme_bw()
```

```{r tbl-generalize-hz-names-tbl, results='asis', echo=FALSE}
# full cross-tab of GHL vs. original designations
cross.tab <- table(loafercreek$genhz, loafercreek$hzname)
# get top-N columns, not including "not-used" row
top.hz <- order(apply(cross.tab[1:length(n), ], 2, sum), decreasing = TRUE)[1:15]
# truncated cross-tabulation
kable(cross.tab[, top.hz], caption = "Generalized Horizon Labels vs. Horizon Designations (truncated counts)")
```

```{r fig-generalize-hz-names, fig.width=10, fig.height=6, echo=FALSE, fig.cap='CAPTION ME'}
# plot generalized horizons via color, sorted by GHL probabilities
loafercreek$genhz.soil_color <- cols[match(loafercreek$genhz, hz.names)]
par(mar=c(0,0,0,0))
plot(loafercreek, color='genhz.soil_color', divide.hz=FALSE, print.id=FALSE, name='', plot.order=h$order)
legend('bottom', legend=hz.names, col=cols, pch=15, bty='n', horiz=TRUE, cex=2)
```

## Aggregation of horizon labels by slicing

```{r fig-slicing-results, fig.width=10, fig.height=6, echo=FALSE, fig.cap='CAPTION ME'}
# graphical check: profiles 1:15, top 25 slices
opar <- par()
par(mfrow=c(2,1), mar=c(0,0,0,0))
plot(loafercreek[1:15, 1:25], name='genhz', id.style='side', cex.names=0.9)
plot(s[1:15, 1:25], name='genhz', id.style='side', cex.names=0.9)
par(opar)
```

```{r fig-genhz-depths, fig.width=10, fig.height=8, echo=FALSE, fig.cap='CAPTION ME'}
# plot depth-ranges of generalized horizon slices
bwplot(hzdept ~ genhz, data=horizons(s), ylim=c(155, -5), ylab='Generalized Horizon Depth (cm)', scales=list(y=list(tick.number=10)), asp=1, panel=function(...) {
	panel.abline(h=seq(0, 140, by=10), v=1:length(hz.names),col=grey(0.8), lty=3)
	panel.bwplot(...)
})
```

## ML Horizon boundaries

```{r fig-assumptions-po-model, echo=FALSE, fig.width=5, fig.height=5, fig.cap='CAPTION ME'}
## check assumptions of PO model: pp. 351 in (Harell, 2001)
plot.xmean.ordinaly(genhz ~ hzdept, data=horizons(s))
```

```{r tbl-po-model, echo=FALSE}
# we need to find a much cleaner way to report those results!
print(l.genhz)
```

```{r fig-ml-hz-boundaries, fig.width=10, fig.height=5, echo=FALSE, fig.cap = 'CAPTION ME'}
p.1 <- xyplot(top ~ value | variable, groups=which, data=g, type='l', ylim=c(155, -5), xlim=c(-0.1,1.2), auto.key=list(columns=2, points=FALSE, lines=TRUE), as.table=TRUE, par.settings=list(superpose.line=list(lwd=1, lty=1, col=c('blue','black','red'))), layout=c(8,1), scales=list(y=list(alternating=3, tick.number=10), x=list(alternating=1)), xlab='Probability', ylab='Depth (cm)', strip=strip.custom(bg=grey(0.85)), panel=function(...) {
	panel.abline(h=seq(0, 140, by=10), v=seq(0, 1, by=0.2), col=grey(0.8), lty=3)
	panel.xyplot(...)
})

# add hz-boundaries by slicing vs. PO model
p.1 + latticeExtra::layer(panel.text(x=1, y=a.ml$top[-1], label=expression(symbol("\254")), col='blue', cex=1)) + latticeExtra::layer(panel.text(x=1, y=p.ml$top[-1], label=expression(symbol("\254")), col='red', cex=1))
```

```{r fig-ml-hz-boundaries-2, fig.width=5, fig.height=5, echo=FALSE, fig.cap = 'CAPTION ME'}
# compare slicing vs. PO-LR
xyplot(top ~ value | which, groups=variable, data=g, type='l', ylim=c(155, -5), xlim=c(-0.1,1.2), auto.key=list(space='right', columns=1, points=FALSE, lines=TRUE, cex=2, title='GHL'), as.table=TRUE, par.settings=list(superpose.line=list(col=cols, lwd=2, lty=1), layout.heights=list(strip=1.5)), scales=list(cex=1.25, y=list(alternating=3, tick.number=10), x=list(alternating=1)), xlab=list('Probability', cex=1.25), ylab=list('Depth (cm)', cex=1.25), strip=strip.custom(par.strip.text=list(cex=1.5), bg=grey(0.85)), asp=1.5, panel=function(...) {
  panel.abline(h=seq(0, 140, by=10), v=seq(0, 1, by=0.2), col=grey(0.8), lty=3)
  panel.xyplot(...)
})
```

```{r tbl-ml-hz-boundaries, echo=FALSE, results='asis'}
# print hz boundary tables
hz_bnd_tbl <- cbind(a.ml, p.ml)
names(hz_bnd_tbl) <- rep(c('Horizon', 'Top (cm)', 'Bottom (cm)', 'Confidence', 'Brier'), times = 2)
kable(hz_bnd_tbl, digits = 2, caption = 'CAPTION ME')
```

## Brier Score Evaluation of ML Horizon Labels

```{r tbl-brier-scores, echo=FALSE}
# larger values -> predictions are less consistently correct
kable(p.bs, digits = 2, caption = "CAPTION ME")
```

```{r fig-brier-scores, fig.width=10, fig.height=5, echo=FALSE, fig.cap='CAPTION ME'}
# make plot of jittered slice-depths vs. fake probability, colored by genhz label
p.3 <- xyplot(jitter(hzdept) ~ jitter(fake.prob, factor=2), groups=genhz, data=p.s, cex=0.25, pch=15, par.settings=list(superpose.symbol=list(col=alpha(cols, 0.5))))

# combine with model output
p.2 + p.3
```

## Model Stability

Predictions from the 250 models were then combined and visualized below. 

```{r fig-model-robustness, fig.width=10, fig.height=5, echo=FALSE}
# plot with transparency
xyplot(top ~ value | variable, data=d.res, type='l', ylim=c(155, -5), xlim=c(-0.1,1.1), auto.key=list(columns=3, points=FALSE, lines=TRUE), as.table=TRUE, par.settings=list(plot.line=list(lwd=1, lty=1, col=rgb(0, 0, 0.75, alpha=0.025))), layout=c(8,1), scales=list(y=list(alternating=3, tick.number=10), x=list(alternating=1)), xlab='Probability', ylab='Depth (cm)', strip=strip.custom(bg=grey(0.85)), panel=function(...) {
	panel.abline(h=seq(0, 140, by=10), v=seq(0, 1, by=0.2), col=grey(0.8), lty=3)
	panel.xyplot(...)
})

# plot model accuracy: not all models are equal! (in terms of quality)
# plot(density(na.omit(res.mdi)), main='Model Discrimination Index (R2)')
#
# (We can describe these stats uin the text as we already have quite a lot of figures)
#
```

```{r tbl-model-robustness, echo=FALSE}
# cast to wide format
d.res.wide <- cast(d.res, .id + top ~ variable, value='value')
d.res.wide$bottom <- d.res.wide$top + 1

# compute ML horizonation, by rep
# consider weighting by model Dxy
sim.ml <- ddply(d.res.wide, '.id', get.ml.hz, o.names=hz.names)

# aggregate ML horizonation over reps
res.robust <- ddply(sim.ml, 'hz', plyr::summarize, top=paste(round(quantile(top, probs=c(0.05, 0.5, 0.95))), collapse='-'), bottom=paste(round(quantile(bottom, probs=c(0.05, 0.5, 0.95))), collapse='-'), psuedo.brier=paste(round(quantile(pseudo.brier, probs=c(0.05, 0.5, 0.95)), 3), collapse='-'))

kable(res.robust, digits = 2, caption = "CAPTION ME")
```

# Conclusions

# References

